本文主要针对C++中并发编程相关内容:

- 多线程
- 锁







[C++ 并发编程（从C++11到C++17） (paul.pub)](https://paul.pub/cpp-concurrency/)



###### 引入读写控制

在这篇文章的第6个实验中有一个很有意思的现象,即多线程并行计算下导致的结果错误

**问题描述**

实验想要求 从1到max的自然数的平方之和, 为了优化计算速度,提出了并行的idea

- 串行: 逐个计算,然后累加
- 并行: 按照hard_concurrency,即硬件所能支持的线程并行度,将任务进行划分,每个线程处理一部分的数据,然后再将结果累加

程序从逻辑上来看是正确的,但是运行之后的结果并不能和串行模式下结果相吻合,即结果错误.



**背景介绍**	

每个处理器都会有其自己的cache,当处理器进行计算时,高速缓存会介入,此时,cache和memory之间会存在不一致的情况,cache中的内容还未及时的写入到memory中

此时focus到这句代码上:

```cpp
void worker(int min, int max) {
  for (int i = min; i <= max; i++) {
    sum += sqrt(i);
  }
}
```

这里的sum是全局变量,是属于进程的资源,线程执行时会直接将当前的结果叠加到sum上,这个叠加的动作并非是原子化的,即需要一系列的读写寄存器的动作,

所以这里就会存在各自线程同时对sum的某一时刻的值进行读取,于是这里就产生了错误的结果

所以这是一个较为直接的,对多线程下共享数据的访问时引入读写控制的例子,对于共享数据的使用的代码就是 临界区



**解决方法**

对于这个问题,我们可以看到,每个线程的任务有两部分,计算和读写结果,显然计算这部分各个线程之间是独立的,所以只需要考虑对于sum的读写这一部分的控制,即我们想要每个时刻只有一个线程对该数据进行读写.



**mutex**

对于mutex的各种类型以及共有的函数接口,文章都介绍的很详细





- **超时**：`timed_mutex`，`recursive_timed_mutex`，`shared_timed_mutex`的名称都带有`timed`，这意味着它们都支持超时功能。它们都提供了`try_lock_for`和`try_lock_until`方法，这两个方法分别可以指定超时的时间长度和时间点。如果在超时的时间范围内没有能获取到锁，则直接返回，不再继续等待。
  - 这是基于mutex会无限等待lock作出的改进
- **可重入**：`recursive_mutex`和`recursive_timed_mutex`的名称都带有`recursive`。可重入或者叫做可递归，是指在同一个线程中，同一把锁可以锁定多次。这就避免了一些不必要的死锁。
  - 这一点还不明白
- **共享**：`shared_timed_mutex`和`shared_mutex`提供了共享功能。对于这类互斥体，实际上是提供了两把锁：一把是共享锁，一把是互斥锁。一旦某个线程获取了互斥锁，任何其他线程都无法再获取互斥锁和共享锁；但是如果有某个线程获取到了共享锁，其他线程无法再获取到互斥锁，但是还有获取到共享锁。这里互斥锁的使用和其他的互斥体接口和功能一样。而共享锁可以同时被多个线程同时获取到（使用共享锁的接口见下面的表格）。共享锁通常用在[读者写者模型](https://en.wikipedia.org/wiki/Readers–writers_problem)上。







###### 锁带来的开销

当我们对sum的读写加上锁之后,即使我们的机器具有8个线程,但是速度却大大变慢了,原因在于此时的瓶颈在于对sum的锁过于频繁,没计算出一个部分结果就想要叠加到sum上,所以此时的改进是: 线程对于自己负责的内容,先计算出这个部分的整个结果,再叠加到sum上去,减少了对于sum的读写频率,于是有效地提升了求解速度.

我们应该保证锁的粒度尽可能的细,在这里我们的锁的范围是对sum的叠加

同时我们也应该尽可能地使锁使用的频率低.









































###### latch

[C++20并发编程之线程闩(std::latch)和线程卡(std::barrier)_c++20 latch-CSDN博客](https://blog.csdn.net/qq_51282224/article/details/134479809)